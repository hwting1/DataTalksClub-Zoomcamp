{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Open source data ingestion for RAGs with dlt\n",
    "\n",
    "Video: https://www.youtube.com/watch?v=qUNyfR_X2Mo\n",
    "\n",
    "In this hands-on workshop, we’ll learn how to build a data ingestion pipeline using dlt to load data from a REST API into LanceDB so you can have an always up to date RAG.\n",
    "\n",
    "​We’ll cover the following steps:\n",
    "\n",
    "* Extract data from REST APIs\n",
    "* Loading and vectorizing into LanceDB, which unlike other vector DBs stores the data _and_ the embeddings\n",
    "* Incremental loading\n",
    "\n",
    "​By the end of this workshop, you’ll be able to write a portable, OSS data pipeline for your RAG that you can deploy anywhere, such as python notebooks, virtual machines, or orchestrators like Airflow, Dagster or Mage."
   ],
   "id": "318b932a99e5d501"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Resources\n",
    "\n",
    "* Slides: [dlt-LLM-Zoomcamp.pdf](https://github.com/user-attachments/files/16131729/dlt.LLM.Zoomcamp.pdf)\n",
    "* [Google Colab notebook](https://colab.research.google.com/drive/1nNOybHdWQiwUUuJFZu__xvJxL_ADU3xl?usp=sharing) - make a copy to follow along!"
   ],
   "id": "6266460648ee6053"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Homework\n",
    "\n",
    "In the workshop, we extracted contents from two pages in notion titled \"Workshop: Benefits and Perks\" and \"Workshop: Working hours, PTO, and Vacation\". \n",
    "\n",
    "Repeat the same process for a third page titled \"Homework: Employee handbook\" (hidden from public view, but accessible via API key):\n",
    "\n",
    "1. Modify the REST API source to extract only this page.\n",
    "2. Write the output into a separate table called \"homework\".\n",
    "3. Remember to update the table name in all cells where you connect to a lancedb table.\n",
    "\n",
    "To do this you can use the [workshop Colab](https://colab.research.google.com/drive/1nNOybHdWQiwUUuJFZu__xvJxL_ADU3xl?usp=sharing) as a basis.\n",
    "\n",
    "Now, answer the following questions:  "
   ],
   "id": "447cd775884cd871"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:35.514536Z",
     "start_time": "2024-07-11T15:15:25.746393Z"
    }
   },
   "cell_type": "code",
   "source": "!yes | dlt init rest_api lancedb",
   "id": "97824211ae70945d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up the init scripts in \u001B[1mhttps://github.com/dlt-hub/verified-sources.git\u001B[0m...\r\n",
      "Cloning and configuring a verified source \u001B[1mrest_api\u001B[0m (Generic API Source)\r\n",
      "Do you want to proceed? [Y/n]: \r\n",
      "Verified source \u001B[1mrest_api\u001B[0m was added to your project!\r\n",
      "* See the usage examples and code snippets to copy from \u001B[1mrest_api_pipeline.py\u001B[0m\r\n",
      "* Add credentials for \u001B[1mlancedb\u001B[0m and other secrets in \u001B[1m./.dlt/secrets.toml\u001B[0m\r\n",
      "* \u001B[1mrequirements.txt\u001B[0m was created. Install it with:\r\n",
      "pip3 install -r requirements.txt\r\n",
      "* Read \u001B[1mhttps://dlthub.com/docs/walkthroughs/create-a-pipeline\u001B[0m for more information\r\n",
      "yes: standard output: Broken pipe\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:36.826022Z",
     "start_time": "2024-07-11T15:15:35.516675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import datetime, timezone\n",
    "import dlt\n",
    "import lancedb\n",
    "from openai import OpenAI\n",
    "from dlt.sources.helpers.rest_client.paginators import BasePaginator, JSONResponsePaginator\n",
    "from dlt.sources.helpers.requests import Response, Request\n",
    "from dlt.destinations.adapters import lancedb_adapter\n",
    "from rest_api import RESTAPIConfig, rest_api_source"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:36.829249Z",
     "start_time": "2024-07-11T15:15:36.826933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL_PROVIDER\"] = \"sentence-transformers\"\n",
    "os.environ[\"DESTINATION__LANCEDB__EMBEDDING_MODEL\"] = \"all-MiniLM-L6-v2\"\n",
    "os.environ[\"DESTINATION__LANCEDB__CREDENTIALS__URI\"] = \".lancedb\""
   ],
   "id": "300c65a0632a740e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:50.710165Z",
     "start_time": "2024-07-11T15:15:36.830283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PostBodyPaginator(BasePaginator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cursor = None\n",
    "\n",
    "    def update_state(self, response: Response) -> None:\n",
    "        # Assuming the API returns an empty list when no more data is available\n",
    "        if not response.json():\n",
    "            self._has_next_page = False\n",
    "        else:\n",
    "            self.cursor = response.json().get(\"next_cursor\")\n",
    "            if self.cursor is None:\n",
    "                self._has_next_page = False\n",
    "\n",
    "    def update_request(self, request: Request) -> None:\n",
    "        if request.json is None:\n",
    "            request.json = {}\n",
    "\n",
    "        # Add the cursor to the request body\n",
    "        request.json[\"start_cursor\"] = self.cursor\n",
    "\n",
    "@dlt.resource(name=\"homework\")\n",
    "def rest_api_notion_resource():\n",
    "    notion_config: RESTAPIConfig = {\n",
    "        \"client\": {\n",
    "            \"base_url\": \"https://api.notion.com/v1/\",\n",
    "            \"auth\": {\n",
    "                \"token\": dlt.secrets[\"sources.rest_api.notion.api_key\"]\n",
    "            },\n",
    "            \"headers\":{\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Notion-Version\": \"2022-06-28\"\n",
    "            }\n",
    "        },\n",
    "        \"resources\": [\n",
    "            {\n",
    "                \"name\": \"search\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"search\",\n",
    "                    \"method\": \"POST\",\n",
    "                    \"paginator\": PostBodyPaginator(),\n",
    "                    \"json\": {\n",
    "                        \"query\": \"homework\",\n",
    "                        \"sort\": {\n",
    "                            \"direction\": \"ascending\",\n",
    "                            \"timestamp\": \"last_edited_time\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"data_selector\": \"results\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"page_content\",\n",
    "                \"endpoint\": {\n",
    "                    \"path\": \"blocks/{page_id}/children\",\n",
    "                    \"paginator\": JSONResponsePaginator(),\n",
    "                    \"params\": {\n",
    "                        \"page_id\": {\n",
    "                            \"type\": \"resolve\",\n",
    "                            \"resource\": \"search\",\n",
    "                            \"field\": \"id\"\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    yield from rest_api_source(notion_config,name=\"homework\")\n",
    "\n",
    "def extract_page_content(response):\n",
    "    block_id = response[\"id\"]\n",
    "    last_edited_time = response[\"last_edited_time\"]\n",
    "    block_type = response.get(\"type\", \"Not paragraph\")\n",
    "    if block_type != \"paragraph\":\n",
    "        content = \"\"\n",
    "    else:\n",
    "        try:\n",
    "            content = response[\"paragraph\"][\"rich_text\"][0][\"plain_text\"]\n",
    "        except IndexError:\n",
    "            content = \"\"\n",
    "    return {\n",
    "        \"block_id\": block_id,\n",
    "        \"block_type\": block_type,\n",
    "        \"content\": content,\n",
    "        \"last_edited_time\": last_edited_time,\n",
    "        \"inserted_at_time\": datetime.now(timezone.utc)\n",
    "    }\n",
    "\n",
    "@dlt.resource(\n",
    "    name=\"homework\",\n",
    "    write_disposition=\"merge\",\n",
    "    primary_key=\"block_id\",\n",
    "    columns={\"last_edited_time\":{\"dedup_sort\":\"desc\"}}\n",
    ")\n",
    "def rest_api_notion_incremental(\n",
    "        last_edited_time = dlt.sources.incremental(\"last_edited_time\", initial_value=\"2024-06-26T08:16:00.000Z\",primary_key=(\"block_id\"))\n",
    "):\n",
    "    # last_value = last_edited_time.last_value\n",
    "    # print(last_value)\n",
    "\n",
    "    for block in rest_api_notion_resource.add_map(extract_page_content):\n",
    "        if not(len(block[\"content\"])):\n",
    "            continue\n",
    "        yield block\n",
    "\n",
    "def load_notion() -> None:\n",
    "    pipeline = dlt.pipeline(\n",
    "        pipeline_name=\"company_policies\",\n",
    "        destination=\"lancedb\",\n",
    "        dataset_name=\"notion_pages\",\n",
    "        # full_refresh=True\n",
    "    )\n",
    "\n",
    "    load_info = pipeline.run(\n",
    "        lancedb_adapter(\n",
    "            rest_api_notion_incremental,\n",
    "            embed=\"content\"\n",
    "        ),\n",
    "        table_name=\"homework\",\n",
    "        write_disposition=\"merge\"\n",
    "    )\n",
    "    print(load_info)\n",
    "\n",
    "load_notion()"
   ],
   "id": "57c4cd303837d852",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwting/anaconda3/envs/rapids/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline company_policies load step completed in 10.13 seconds\n",
      "1 load package(s) were loaded to destination LanceDB and into dataset notion_pages\n",
      "The LanceDB destination used <dlt.destinations.impl.lancedb.configuration.LanceDBCredentials object at 0x7f32c0e1d4d0> location to store data\n",
      "Load package 1720710936.9023495 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Q1. Rows in LanceDB\n",
    "\n",
    "How many rows does the lancedb table \"notion_pages__homework\" have?"
   ],
   "id": "97ec11e878107588"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:50.723157Z",
     "start_time": "2024-07-11T15:15:50.711997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = lancedb.connect(\".lancedb\")\n",
    "dbtable = db.open_table(\"notion_pages___homework\")\n",
    "df = dbtable.to_pandas()\n",
    "print(f\"The lancedb table 'notion_pages__homework' have {df.shape[0]} rows\")"
   ],
   "id": "2e7185bfe4022a77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lancedb table 'notion_pages__homework' have 17 rows\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Q2. Running the Pipeline: Last edited time\n",
    "\n",
    "In the demo, we created an incremental dlt resource `rest_api_notion_incremental` that keeps track of `last_edited_time`. What value does it store after you've run your pipeline once? (Hint: you will be able to get this value by performing some aggregation function on the column `last_edited_time` of the table)"
   ],
   "id": "b33d47f095d3917d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:15:50.738465Z",
     "start_time": "2024-07-11T15:15:50.724296Z"
    }
   },
   "cell_type": "code",
   "source": "print(f\"The last edited time after I've run my pipline once is {df['last_edited_time'].max()}\")",
   "id": "5d4be1592b22abd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last edited time after I've run my pipline once is 2024-07-05 23:33:00+00:00\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Q3. Ask the Assistant \n",
    "\n",
    "Find out with the help of the AI assistant: how many PTO days are the employees entitled to in a year?  "
   ],
   "id": "c099c9e29300407d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T15:16:08.262715Z",
     "start_time": "2024-07-11T15:15:50.739567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_context_from_lancedb(dbtable, question, top_k=2):\n",
    "\n",
    "    query_results = dbtable.search(query=question).to_list()\n",
    "    context = \"\\n\".join([result[\"content\"] for result in query_results[:top_k]])\n",
    "    return context\n",
    "        \n",
    "def rag_from_lancedb(query, db_name, table_name):\n",
    "    # Connect to the lancedb table\n",
    "    db = lancedb.connect(db_name)\n",
    "    dbtable = db.open_table(table_name)\n",
    "\n",
    "    # A system prompt telling OpenAI to accept input in the form of \"Question: ... ; Context: ...\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that helps users understand policies inside a company's employee handbook. The user will first ask you a question and then provide you relevant paragraphs from the handbook as context. Please answer the question based on the provided context. For any details missing in the paragraph, encourage the employee to contact the HR for that information. Please keep the responses conversational.\"}\n",
    "    ]\n",
    "\n",
    "    # Retrieve the relevant paragraphs on the question\n",
    "    context = retrieve_context_from_lancedb(dbtable, query, top_k=2)\n",
    "    messages.append(\n",
    "        {\"role\": \"user\", \"content\": f\"Question: '{query}'; Context: '{context}'\"}\n",
    "    )\n",
    "\n",
    "    client = OpenAI(\n",
    "        base_url='http://localhost:11434/v1/',\n",
    "        api_key='ollama',\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gemma:2b',\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    response_content = response.choices[0].message.content\n",
    "    print(f\"Question: {query}\")\n",
    "    print(f\"Assistant: {response_content}\")\n",
    "    return response_content\n",
    "    \n",
    "\n",
    "db_name = \".lancedb\"\n",
    "table_name = \"notion_pages___homework\"\n",
    "query = \"how many PTO days are the employees entitled to in a year?\"\n",
    "res = rag_from_lancedb(query, db_name, table_name)"
   ],
   "id": "df8d5ca601781e6d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwting/anaconda3/envs/rapids/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: how many PTO days are the employees entitled to in a year?\n",
      "Assistant: Sure, here is the answer:\n",
      "\n",
      "Hi! It seems you're curious about the number of PTO days employees are entitled to in a year. According to the handbook, employees receive 30 days of paid time off (PTO) per year.\n",
      "\n",
      "However, it's important to note that these 30 days can be spread out throughout the year, with each employee receiving 2.5 days per month. You can take your PTO at any time after your first week with us, and you can use any time off you haven't accrued yet.\n",
      "\n",
      "If you'd like to use your PTO, you can submit a request through our HRIS. Your manager or HR must approve your leave before you can take it.\n",
      "\n",
      "Please don't hesitate to contact the HR department if you have any further questions or concerns about your PTO rights.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Submit the results\n",
    "\n",
    "* Submit your results here: https://courses.datatalks.club/llm-zoomcamp-2024/homework/workshop1\n",
    "* It's possible that your answers won't match exactly. If it's the case, select the closest one."
   ],
   "id": "d125b3dea128e7e0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
