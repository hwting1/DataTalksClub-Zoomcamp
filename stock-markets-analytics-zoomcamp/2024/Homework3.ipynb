{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a562b0af-edea-445c-8562-ac85e01da0dd",
   "metadata": {},
   "source": [
    "# Module 3 Homework\n",
    "\n",
    "In this homework, we're going to work with categorical variables, first ML models (Decision Trees), and hyperparameter tuning.\n",
    "\n",
    "Please use the [Colab Module 3](https://github.com/DataTalksClub/stock-markets-analytics-zoomcamp/blob/main/03-modeling/Module_3_Colab_Time_Series_Modeling.ipynb) for all tasks to ensure you have the same dataframe used for the Modeling part, as covered during the lecture. \n",
    "We suggest copying and extending it (around \"TODO\" comments).\n",
    "\n",
    "**HINT**: If you want to avoid data truncation in GitHub's UI, try either of the following options:\n",
    "* Open the notebook in [Colab, using the GitHub link to the notebook](https://colab.research.google.com/github/DataTalksClub/stock-markets-analytics-zoomcamp/blob/main/03-modeling/Module_3_Colab_Time_Series_Modeling.ipynb).\n",
    "* Clone the repository to a local folder and open the notebook in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:40.062746Z",
     "start_time": "2024-06-16T01:56:39.400616Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "33f08dc4-2db8-4216-8b07-25d7a7f31730",
   "metadata": {},
   "source": [
    "## Question 1 (1 point): Dummies on Month and Week-of-Month\n",
    "\n",
    "**Find the ABSOLUTE CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable `is_positive_growth_5d_future`?**\n",
    "\n",
    "You saw in the correlation analysis and modeling that September and October may be important seasonal months. In this task, we'll go futher and try to generate dummies for Month and Week-of-month (starting from 1). For example, the first week of October should be coded similar to this: 'October_w1'.\n",
    "Once you've generated the new set of variables, find the most correlated (in absolute value) one with `is_positive_growth_5d_future` and round it to 3 digits after the comma.\n",
    "\n",
    "Suggested path to a solution:\n",
    "- [[Source](https://stackoverflow.com/questions/25249033/week-of-a-month-pandas)] Use this formula to get the week of month for the datetime variable d: `(d.day-1)//7+1` \n",
    "- Define a new string variable for all month-week_of_month combinations. Append it to the CATEGORICAL features set. You should have 5 variables treated as CATEGORICAL now: 'Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom'. In the end, you should get 115 dummy features, including 60 (=12*5) week_month_of_week dummies.\n",
    "- Use [pandas.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) to generate dummies.\n",
    "- Use [pandas.DataFrame.corr()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html) function (also used in [Code Snippet 1]) to get correlations with `is_positive_growth_5d_future`, filter out only variables representing the new dummy set, and sort it by absolute values (you can define a new column \"abs_corr\" in the dataframe with correlations), and find the highest value (among the new dummies features set).\n",
    "\n",
    "**NOTE**: new dummies will be used as features in the next tasks, please leave them in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "id": "5e9ddbf9-71cb-433a-a3bd-a7db5bafd7f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:40.284282Z",
     "start_time": "2024-06-16T01:56:40.063877Z"
    }
   },
   "source": [
    "df = pd.read_parquet(\"stocks_df_combined_2024_05_07.parquet.brotli\")\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "0        0.088542     0.101563     0.088542     0.097222     0.060163   \n",
       "1        0.097222     0.102431     0.097222     0.100694     0.062311   \n",
       "2        0.100694     0.103299     0.100694     0.102431     0.063386   \n",
       "3        0.102431     0.103299     0.098958     0.099826     0.061774   \n",
       "4        0.099826     0.100694     0.097222     0.098090     0.060700   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "5426  3479.399902  3496.000000  3425.000000  3427.750000  3427.750000   \n",
       "\n",
       "            Volume Ticker  Year      Month  Weekday  ... growth_brent_oil_7d  \\\n",
       "0     1.031789e+09   MSFT  1986 1986-03-01        3  ...                 NaN   \n",
       "1     3.081600e+08   MSFT  1986 1986-03-01        4  ...                 NaN   \n",
       "2     1.331712e+08   MSFT  1986 1986-03-01        0  ...                 NaN   \n",
       "3     6.776640e+07   MSFT  1986 1986-03-01        1  ...                 NaN   \n",
       "4     4.789440e+07   MSFT  1986 1986-03-01        2  ...                 NaN   \n",
       "...            ...    ...   ...        ...      ...  ...                 ...   \n",
       "5422  1.571996e+06  LT.NS  2024 2024-04-01        1  ...            1.006530   \n",
       "5423  3.748847e+06  LT.NS  2024 2024-05-01        3  ...            0.946279   \n",
       "5424  4.079696e+06  LT.NS  2024 2024-05-01        4  ...            0.942513   \n",
       "5425  2.614667e+06  LT.NS  2024 2024-05-01        0  ...            0.936187   \n",
       "5426  3.375099e+06  LT.NS  2024 2024-05-01        1  ...            0.928603   \n",
       "\n",
       "      growth_brent_oil_30d  growth_brent_oil_90d  growth_brent_oil_365d  \\\n",
       "0                      NaN                   NaN                    NaN   \n",
       "1                      NaN                   NaN                    NaN   \n",
       "2                      NaN                   NaN                    NaN   \n",
       "3                      NaN                   NaN                    NaN   \n",
       "4                      NaN                   NaN                    NaN   \n",
       "...                    ...                   ...                    ...   \n",
       "5422              1.011164              1.108923               0.936075   \n",
       "5423              0.973473              1.053911               0.931945   \n",
       "5424              0.967125              1.049197               0.946816   \n",
       "5425              0.975418              1.027877               0.952887   \n",
       "5426              0.958040              1.043440               0.940584   \n",
       "\n",
       "      growth_btc_usd_1d  growth_btc_usd_3d  growth_btc_usd_7d  \\\n",
       "0                   NaN                NaN                NaN   \n",
       "1                   NaN                NaN                NaN   \n",
       "2                   NaN                NaN                NaN   \n",
       "3                   NaN                NaN                NaN   \n",
       "4                   NaN                NaN                NaN   \n",
       "...                 ...                ...                ...   \n",
       "5422           0.949809           0.956129           0.913106   \n",
       "5423           1.014925           0.926103           0.916902   \n",
       "5424           1.063704           1.037155           0.986425   \n",
       "5425           0.986426           1.004327           0.989362   \n",
       "5426           0.999541           0.988129           1.041165   \n",
       "\n",
       "      growth_btc_usd_30d  growth_btc_usd_90d  growth_btc_usd_365d  \n",
       "0                    NaN                 NaN                  NaN  \n",
       "1                    NaN                 NaN                  NaN  \n",
       "2                    NaN                 NaN                  NaN  \n",
       "3                    NaN                 NaN                  NaN  \n",
       "4                    NaN                 NaN                  NaN  \n",
       "...                  ...                 ...                  ...  \n",
       "5422            0.850046            1.423982             2.158543  \n",
       "5423            0.903379            1.369046             2.038296  \n",
       "5424            0.953153            1.462818             2.180063  \n",
       "5425            0.916771            1.465996             2.219715  \n",
       "5426            0.910188            1.424538             2.279641  \n",
       "\n",
       "[221142 rows x 202 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>growth_brent_oil_7d</th>\n",
       "      <th>growth_brent_oil_30d</th>\n",
       "      <th>growth_brent_oil_90d</th>\n",
       "      <th>growth_brent_oil_365d</th>\n",
       "      <th>growth_btc_usd_1d</th>\n",
       "      <th>growth_btc_usd_3d</th>\n",
       "      <th>growth_btc_usd_7d</th>\n",
       "      <th>growth_btc_usd_30d</th>\n",
       "      <th>growth_btc_usd_90d</th>\n",
       "      <th>growth_btc_usd_365d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.101563</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.060163</td>\n",
       "      <td>1.031789e+09</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.062311</td>\n",
       "      <td>3.081600e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>1.331712e+08</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.102431</td>\n",
       "      <td>0.103299</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.061774</td>\n",
       "      <td>6.776640e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.097222</td>\n",
       "      <td>0.098090</td>\n",
       "      <td>0.060700</td>\n",
       "      <td>4.789440e+07</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>1986</td>\n",
       "      <td>1986-03-01</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1.571996e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-04-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006530</td>\n",
       "      <td>1.011164</td>\n",
       "      <td>1.108923</td>\n",
       "      <td>0.936075</td>\n",
       "      <td>0.949809</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.913106</td>\n",
       "      <td>0.850046</td>\n",
       "      <td>1.423982</td>\n",
       "      <td>2.158543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3.748847e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.946279</td>\n",
       "      <td>0.973473</td>\n",
       "      <td>1.053911</td>\n",
       "      <td>0.931945</td>\n",
       "      <td>1.014925</td>\n",
       "      <td>0.926103</td>\n",
       "      <td>0.916902</td>\n",
       "      <td>0.903379</td>\n",
       "      <td>1.369046</td>\n",
       "      <td>2.038296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4.079696e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942513</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>1.049197</td>\n",
       "      <td>0.946816</td>\n",
       "      <td>1.063704</td>\n",
       "      <td>1.037155</td>\n",
       "      <td>0.986425</td>\n",
       "      <td>0.953153</td>\n",
       "      <td>1.462818</td>\n",
       "      <td>2.180063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2.614667e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936187</td>\n",
       "      <td>0.975418</td>\n",
       "      <td>1.027877</td>\n",
       "      <td>0.952887</td>\n",
       "      <td>0.986426</td>\n",
       "      <td>1.004327</td>\n",
       "      <td>0.989362</td>\n",
       "      <td>0.916771</td>\n",
       "      <td>1.465996</td>\n",
       "      <td>2.219715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>3479.399902</td>\n",
       "      <td>3496.000000</td>\n",
       "      <td>3425.000000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3.375099e+06</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>2024-05-01</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928603</td>\n",
       "      <td>0.958040</td>\n",
       "      <td>1.043440</td>\n",
       "      <td>0.940584</td>\n",
       "      <td>0.999541</td>\n",
       "      <td>0.988129</td>\n",
       "      <td>1.041165</td>\n",
       "      <td>0.910188</td>\n",
       "      <td>1.424538</td>\n",
       "      <td>2.279641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>221142 rows × 202 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f7a1ce8b0d867fd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:42.038647Z",
     "start_time": "2024-06-16T01:56:40.285021Z"
    }
   },
   "source": [
    "GROWTH = [g for g in df.keys() if (g.find('growth_')==0)&(g.find('future')<0)]\n",
    "OHLCV = ['Open','High','Low','Close','Adj Close_x','Volume']\n",
    "TO_PREDICT = [g for g in df.keys() if (g.find('future')>=0)]\n",
    "df['ln_volume'] = df.Volume.apply(lambda x: np.log(x))\n",
    "CUSTOM_NUMERICAL = ['SMA10', 'SMA20', 'growing_moving_average', 'high_minus_low_relative','volatility', 'ln_volume']\n",
    "TECHNICAL_INDICATORS = ['adx', 'adxr', 'apo', 'aroon_1','aroon_2', 'aroonosc',\n",
    "                        'bop', 'cci', 'cmo','dx', 'macd', 'macdsignal', 'macdhist', 'macd_ext',\n",
    "                        'macdsignal_ext', 'macdhist_ext', 'macd_fix', 'macdsignal_fix',\n",
    "                        'macdhist_fix', 'mfi', 'minus_di', 'mom', 'plus_di', 'dm', 'ppo',\n",
    "                        'roc', 'rocp', 'rocr', 'rocr100', 'rsi', 'slowk', 'slowd', 'fastk',\n",
    "                        'fastd', 'fastk_rsi', 'fastd_rsi', 'trix', 'ultosc', 'willr',\n",
    "                        'ad', 'adosc', 'obv', 'atr', 'natr', 'ht_dcperiod', 'ht_dcphase',\n",
    "                        'ht_phasor_inphase', 'ht_phasor_quadrature', 'ht_sine_sine', 'ht_sine_leadsine',\n",
    "                        'ht_trendmod', 'avgprice', 'medprice', 'typprice', 'wclprice']\n",
    "TECHNICAL_PATTERNS = [g for g in df.keys() if g.find('cdl')>=0]\n",
    "MACRO = ['gdppot_us_yoy', 'gdppot_us_qoq', 'cpi_core_yoy', 'cpi_core_mom', 'FEDFUNDS',\n",
    "         'DGS1', 'DGS5', 'DGS10']\n",
    "NUMERICAL = GROWTH + TECHNICAL_INDICATORS + TECHNICAL_PATTERNS + CUSTOM_NUMERICAL + MACRO\n",
    "\n",
    "\n",
    "def create_week_of_month(row):\n",
    "    month = row.month_name()\n",
    "    week = (row.day - 1) // 7 + 1\n",
    "    return month + \"_w\" + str(week)\n",
    "df[\"month_wom\"] = df[\"Date\"].apply(create_week_of_month)\n",
    "\n",
    "CATEGORICAL = ['Month', 'Weekday', 'Ticker', 'ticker_type', 'month_wom']\n",
    "TO_DROP = ['Year','Date','index_x', 'index_y', 'index', 'Quarter','Adj Close_y'] + CATEGORICAL + OHLCV\n",
    "OTHER = [k for k in df.keys() if k not in OHLCV + CATEGORICAL + NUMERICAL + TO_DROP]\n",
    "\n",
    "df.loc[:,'Month'] = df.Month.dt.strftime('%B')\n",
    "df.loc[:,'Weekday'] = df.Weekday.astype(str)\n",
    "\n",
    "dummy_variables = pd.get_dummies(df[CATEGORICAL], dtype='int32')\n",
    "DUMMIES = dummy_variables.keys().to_list()\n",
    "df_with_dummies = pd.concat([df, dummy_variables], axis=1)\n",
    "df_with_dummies = df_with_dummies[df[\"Date\"]>='2000-01-01']"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26744/3093481184.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  df['ln_volume'] = df.Volume.apply(lambda x: np.log(x))\n",
      "/tmp/ipykernel_26744/3093481184.py:31: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['March' 'March' 'March' ... 'May' 'May' 'May']' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,'Month'] = df.Month.dt.strftime('%B')\n",
      "/tmp/ipykernel_26744/3093481184.py:32: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['3' '4' '0' ... '4' '0' '1']' has dtype incompatible with int32, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:,'Weekday'] = df.Weekday.astype(str)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bb257dec-c02b-4aa8-9292-fdb00c3291e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.229074Z",
     "start_time": "2024-06-16T01:56:42.039615Z"
    }
   },
   "source": [
    "corr_df = df_with_dummies[DUMMIES + [\"is_positive_growth_5d_future\"]].corr()\n",
    "growth_5d_corr = corr_df[\"is_positive_growth_5d_future\"].drop('is_positive_growth_5d_future')\n",
    "max_idx = growth_5d_corr.abs().idxmax()\n",
    "print(f\"The CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable ('is_positive_growth_5d_future') is {growth_5d_corr[max_idx]:.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CORRELATION VALUE of the most correlated dummy <month-week_of_month> with the binary outcome variable ('is_positive_growth_5d_future') is -0.035\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "666c18b0d5d13aca",
   "metadata": {},
   "source": [
    "## Question 2 (2 points): Define new \"hand\" rules on macro and technical indicators variables\n",
    "\n",
    "**What is the precision score for the best of the NEW predictions (pred3 or pred4), rounded to 3 digits after the comma?**\n",
    "\n",
    "Let's utilize the knowledge from the visualised tree (clf10) (Code Snippet 5: 1.4.4 Visualisation):\n",
    "\n",
    "* You're asked to define two new 'hand' rules (leading to 'positive' subtrees): \n",
    "  - `pred3_manual_gdp_fastd`: (gdppot_us_yoy <= 0.027) & (fastd >= 0.251)\n",
    "  - `pred4_manual_gdp_wti_oil`: (gdppot_us_yoy >= 0.027) & (growth_wti_oil_30d <= 1.005)\n",
    "\n",
    "* Extend the Code Snippet 3 (Manual \"hand rule\" predictions): Calculate and add new rules (pred3 and pred4) to the dataframe.You should notice that one of the predictions doesn't have any positive predictions on TEST dataset (while it has many on TRAIN+VALIDATION). \n",
    "\n",
    "* Debug: check in the `new_df` and the original dataset/data generation process that we didn't make any mistakes during the data transformation step.\n",
    "\n",
    "* Explain why this can happen even if there are no errors in the data features."
   ]
  },
  {
   "cell_type": "code",
   "id": "71e56542ae73b894",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.523364Z",
     "start_time": "2024-06-16T01:56:45.230441Z"
    }
   },
   "source": [
    "def temporal_split(df, min_date, max_date, train_prop=0.7, val_prop=0.15, test_prop=0.15):\n",
    "    \"\"\"\n",
    "    Splits a DataFrame into three buckets based on the temporal order of the 'Date' column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The DataFrame to split.\n",
    "        min_date (str or Timestamp): Minimum date in the DataFrame.\n",
    "        max_date (str or Timestamp): Maximum date in the DataFrame.\n",
    "        train_prop (float): Proportion of data for training set (default: 0.6).\n",
    "        val_prop (float): Proportion of data for validation set (default: 0.2).\n",
    "        test_prop (float): Proportion of data for test set (default: 0.2).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The input DataFrame with a new column 'split' indicating the split for each row.\n",
    "    \"\"\"\n",
    "    # Define the date intervals\n",
    "    train_end = min_date + pd.Timedelta(days=(max_date - min_date).days * train_prop)\n",
    "    val_end = train_end + pd.Timedelta(days=(max_date - min_date).days * val_prop)\n",
    "\n",
    "    # Assign split labels based on date ranges\n",
    "    split_labels = []\n",
    "    for date in df['Date']:\n",
    "        if date <= train_end:\n",
    "            split_labels.append('train')\n",
    "        elif date <= val_end:\n",
    "            split_labels.append('validation')\n",
    "        else:\n",
    "            split_labels.append('test')\n",
    "\n",
    "    # Add 'split' column to the DataFrame\n",
    "    df['split'] = split_labels\n",
    "\n",
    "    return df\n",
    "\n",
    "min_date_df = df_with_dummies.Date.min()\n",
    "max_date_df = df_with_dummies.Date.max()\n",
    "\n",
    "df_with_dummies = temporal_split(df_with_dummies,\n",
    "                                 min_date = min_date_df,\n",
    "                                 max_date = max_date_df)\n",
    "new_df = df_with_dummies.copy()\n",
    "new_df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open         High          Low        Close  Adj Close_x  \\\n",
       "3490    58.687500    59.312500    56.000000    58.281250    36.065567   \n",
       "3491    56.781250    58.562500    56.125000    56.312500    34.847271   \n",
       "3492    55.562500    58.187500    54.687500    56.906250    35.214706   \n",
       "3493    56.093750    56.937500    54.187500    55.000000    34.035072   \n",
       "3494    54.312500    56.125000    53.656250    55.718750    34.479843   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "5422  3639.000000  3648.949951  3584.050049  3594.300049  3594.300049   \n",
       "5423  3590.050049  3634.149902  3576.050049  3599.500000  3599.500000   \n",
       "5424  3610.000000  3622.000000  3488.449951  3499.800049  3499.800049   \n",
       "5425  3522.800049  3527.000000  3441.100098  3463.300049  3463.300049   \n",
       "5426  3479.399902  3496.000000  3425.000000  3427.750000  3427.750000   \n",
       "\n",
       "          Volume Ticker  Year    Month Weekday  ... month_wom_October_w2  \\\n",
       "3490  53228400.0   MSFT  2000  January       0  ...                    0   \n",
       "3491  54119000.0   MSFT  2000  January       1  ...                    0   \n",
       "3492  64059600.0   MSFT  2000  January       2  ...                    0   \n",
       "3493  54976600.0   MSFT  2000  January       3  ...                    0   \n",
       "3494  62013600.0   MSFT  2000  January       4  ...                    0   \n",
       "...          ...    ...   ...      ...     ...  ...                  ...   \n",
       "5422   1571996.0  LT.NS  2024    April       1  ...                    0   \n",
       "5423   3748847.0  LT.NS  2024      May       3  ...                    0   \n",
       "5424   4079696.0  LT.NS  2024      May       4  ...                    0   \n",
       "5425   2614667.0  LT.NS  2024      May       0  ...                    0   \n",
       "5426   3375099.0  LT.NS  2024      May       1  ...                    0   \n",
       "\n",
       "      month_wom_October_w3  month_wom_October_w4  month_wom_October_w5  \\\n",
       "3490                     0                     0                     0   \n",
       "3491                     0                     0                     0   \n",
       "3492                     0                     0                     0   \n",
       "3493                     0                     0                     0   \n",
       "3494                     0                     0                     0   \n",
       "...                    ...                   ...                   ...   \n",
       "5422                     0                     0                     0   \n",
       "5423                     0                     0                     0   \n",
       "5424                     0                     0                     0   \n",
       "5425                     0                     0                     0   \n",
       "5426                     0                     0                     0   \n",
       "\n",
       "      month_wom_September_w1  month_wom_September_w2  month_wom_September_w3  \\\n",
       "3490                       0                       0                       0   \n",
       "3491                       0                       0                       0   \n",
       "3492                       0                       0                       0   \n",
       "3493                       0                       0                       0   \n",
       "3494                       0                       0                       0   \n",
       "...                      ...                     ...                     ...   \n",
       "5422                       0                       0                       0   \n",
       "5423                       0                       0                       0   \n",
       "5424                       0                       0                       0   \n",
       "5425                       0                       0                       0   \n",
       "5426                       0                       0                       0   \n",
       "\n",
       "      month_wom_September_w4  month_wom_September_w5  split  \n",
       "3490                       0                       0  train  \n",
       "3491                       0                       0  train  \n",
       "3492                       0                       0  train  \n",
       "3493                       0                       0  train  \n",
       "3494                       0                       0  train  \n",
       "...                      ...                     ...    ...  \n",
       "5422                       0                       0   test  \n",
       "5423                       0                       0   test  \n",
       "5424                       0                       0   test  \n",
       "5425                       0                       0   test  \n",
       "5426                       0                       0   test  \n",
       "\n",
       "[182675 rows x 320 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close_x</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>...</th>\n",
       "      <th>month_wom_October_w2</th>\n",
       "      <th>month_wom_October_w3</th>\n",
       "      <th>month_wom_October_w4</th>\n",
       "      <th>month_wom_October_w5</th>\n",
       "      <th>month_wom_September_w1</th>\n",
       "      <th>month_wom_September_w2</th>\n",
       "      <th>month_wom_September_w3</th>\n",
       "      <th>month_wom_September_w4</th>\n",
       "      <th>month_wom_September_w5</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>58.687500</td>\n",
       "      <td>59.312500</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>58.281250</td>\n",
       "      <td>36.065567</td>\n",
       "      <td>53228400.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>56.781250</td>\n",
       "      <td>58.562500</td>\n",
       "      <td>56.125000</td>\n",
       "      <td>56.312500</td>\n",
       "      <td>34.847271</td>\n",
       "      <td>54119000.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>55.562500</td>\n",
       "      <td>58.187500</td>\n",
       "      <td>54.687500</td>\n",
       "      <td>56.906250</td>\n",
       "      <td>35.214706</td>\n",
       "      <td>64059600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>56.093750</td>\n",
       "      <td>56.937500</td>\n",
       "      <td>54.187500</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>34.035072</td>\n",
       "      <td>54976600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>54.312500</td>\n",
       "      <td>56.125000</td>\n",
       "      <td>53.656250</td>\n",
       "      <td>55.718750</td>\n",
       "      <td>34.479843</td>\n",
       "      <td>62013600.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>2000</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>3639.000000</td>\n",
       "      <td>3648.949951</td>\n",
       "      <td>3584.050049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>3594.300049</td>\n",
       "      <td>1571996.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>3590.050049</td>\n",
       "      <td>3634.149902</td>\n",
       "      <td>3576.050049</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3599.500000</td>\n",
       "      <td>3748847.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>3610.000000</td>\n",
       "      <td>3622.000000</td>\n",
       "      <td>3488.449951</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>3499.800049</td>\n",
       "      <td>4079696.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>3522.800049</td>\n",
       "      <td>3527.000000</td>\n",
       "      <td>3441.100098</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>3463.300049</td>\n",
       "      <td>2614667.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>3479.399902</td>\n",
       "      <td>3496.000000</td>\n",
       "      <td>3425.000000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3427.750000</td>\n",
       "      <td>3375099.0</td>\n",
       "      <td>LT.NS</td>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182675 rows × 320 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "78b54769f934b5d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.529930Z",
     "start_time": "2024-06-16T01:56:45.524089Z"
    }
   },
   "source": [
    "new_df['pred0_manual_cci'] = (new_df.cci>200).astype(int)\n",
    "new_df['pred1_manual_prev_g1'] = (new_df.growth_1d>1).astype(int)\n",
    "new_df['pred2_manual_prev_g1_and_snp'] = ((new_df['growth_1d'] > 1) & (new_df['growth_snp500_1d'] > 1)).astype(int)\n",
    "new_df[\"pred3_manual_gdp_fastd\"] = (new_df[\"gdppot_us_yoy\"] <= 0.027) & (new_df[\"fastd\"] >= 0.251).astype(int)\n",
    "new_df[\"pred4_manual_gpd_wti_oil\"] = (new_df[\"gdppot_us_yoy\"] >= 0.027) & (new_df[\"growth_wti_oil_30d\"] <= 1.005).astype(int)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c8a80bede7144399",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.571216Z",
     "start_time": "2024-06-16T01:56:45.530884Z"
    }
   },
   "source": [
    "test_idx = new_df.split.isin(['test'])\n",
    "pred3_score = precision_score(new_df.loc[test_idx, \"is_positive_growth_5d_future\"], new_df.loc[test_idx, \"pred3_manual_gdp_fastd\"], zero_division=0)\n",
    "pred4_score = precision_score(new_df.loc[test_idx, \"is_positive_growth_5d_future\"], new_df.loc[test_idx, \"pred4_manual_gpd_wti_oil\"], zero_division=0)\n",
    "print(f\"The precision score for the best of the NEW variables (pred3 or pred4) is {max(pred3_score, pred4_score):.3f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision score for the best of the NEW variables (pred3 or pred4) is 0.555\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "68db73d97319837",
   "metadata": {},
   "source": [
    "## Question 3 (1 point): Unique correct predictions from a 10-levels deep Decision Tree Classifier (pred5_clf_10) \n",
    "\n",
    "**What is the total number of records in the TEST dataset when the new prediction pred5_clf_10 is better than all 'hand' rules (pred0..pred4)?**\n",
    "\n",
    "NOTE: please include `random_state=42` to Decision Tree Classifier init function (line `clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)`) to ensure everyone gets the same results.\n",
    "\n",
    "Suggested solution:\n",
    "* Step1: Rewrite the '1.4.3 Inference for a decision tree' piece for the Decision Tree Classifier with max_depth=10 (clf_10), so that you fit the model on TRAIN+VALIDATION sets (unchanged from the lecture), but predict on the whole set X_all (to be able to define a new column 'pred5_clf_10' in the dataframe new_df). Here is the [link](https://stackoverflow.com/questions/40729162/merging-results-from-model-predict-with-original-pandas-dataframe) with explanation. It will solve the problem in 1.4.5 when predictions were made only for Test dataset and couldn't be easily joined with the full dataset. \n",
    "\n",
    "* Step2: Once you have it, define a new column 'only_pred5_is_correct' similar to 'hand' prediction rules with several conditions: is_positive_growth_5d_future AND is_correct_pred5 should be equal 1, while all other predictions is_correct_pred0..is_correct_pred4 should be equal to 0.\n",
    "\n",
    "* Step3: Convert 'only_pred5_is_correct' column from bool to int, and find how many times it is equal to 1 in the TEST set. Write down this as an answer.\n",
    "\n",
    "ADVANCED: define a function that can be applied to the whole row of predictions ([a few examples of pandas-apply-row-functions](https://sparkbyexamples.com/pandas/pandas-apply-function-to-every-row/)) and can find whether some prediction 'predX' (where X is one of the predictions) is uniquely correct. It should work even if there are 100 predictions available, so that you don't define manually the condition for 'predX'.  "
   ]
  },
  {
   "cell_type": "code",
   "id": "c549186e78a0f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.574388Z",
     "start_time": "2024-06-16T01:56:45.571905Z"
    }
   },
   "source": [
    "PREDICTIONS = [k for k in new_df.keys() if k.startswith('pred')]\n",
    "PREDICTIONS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pred0_manual_cci',\n",
       " 'pred1_manual_prev_g1',\n",
       " 'pred2_manual_prev_g1_and_snp',\n",
       " 'pred3_manual_gdp_fastd',\n",
       " 'pred4_manual_gpd_wti_oil']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "57e0fb97838b9e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:56:45.979449Z",
     "start_time": "2024-06-16T01:56:45.574943Z"
    }
   },
   "source": [
    "features_list = NUMERICAL + DUMMIES\n",
    "to_predict = 'is_positive_growth_5d_future'\n",
    "new_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "new_df.fillna(0, inplace=True)\n",
    "\n",
    "train_df = new_df[new_df.split.isin(['train','validation'])]\n",
    "test_df = new_df[new_df.split.isin(['test'])]\n",
    "X_train = train_df[features_list]\n",
    "X_test = test_df[features_list]\n",
    "y_train = train_df[to_predict]\n",
    "y_test = test_df[to_predict]\n",
    "SEED = 42"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "95b54e596ec41be2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T01:57:01.170216Z",
     "start_time": "2024-06-16T01:56:45.980555Z"
    }
   },
   "source": [
    "clf_10 = DecisionTreeClassifier(max_depth=10, random_state=SEED)\n",
    "clf_10.fit(X_train, y_train)\n",
    "\n",
    "test_idx = new_df[\"split\"].isin(['test'])\n",
    "new_df.loc[test_idx, \"pred5_clf_10\"] = clf_10.predict(X_test)\n",
    "\n",
    "def check_only_predx_is_correct(row, check_pred, other_preds, to_predict):\n",
    "    correct_pred = (row[check_pred] == row[to_predict])\n",
    "    other_preds_incorrect = all(row[pred] != row[to_predict] for pred in other_preds)\n",
    "    return correct_pred and other_preds_incorrect\n",
    "\n",
    "x = 5\n",
    "other_preds = []\n",
    "for col in new_df.columns:\n",
    "    if col.startswith(f\"pred{x}\"):\n",
    "        check_pred = col\n",
    "    elif col.startswith(\"pred\"):\n",
    "        other_preds.append(col)\n",
    "new_col = f'only_pred_{x}_is_Correct'\n",
    "new_df.loc[test_idx, new_col] = new_df[test_idx].apply(check_only_predx_is_correct, axis=1, check_pred=check_pred, other_preds=other_preds, to_predict=to_predict)\n",
    "\n",
    "print(f\"The total number of records in the TEST dataset when the new prediction pred5_clf_10 is better than all 'hand' rules (pred0..pred4) is {new_df[new_col].sum()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of records in the TEST dataset when the new prediction pred5_clf_10 is better than all 'hand' rules (pred0..pred4) is 1\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "79a82860a1408aba",
   "metadata": {},
   "source": [
    "## Question 4: (2 points) Hyperparameter tuning for a Decision Tree\n",
    "\n",
    "**What is the optimal tree depth (from 1 to 20) for a DecisionTreeClassifier?**\n",
    "\n",
    "NOTE: please include `random_state=42` to Decision Tree Classifier init function (line `clf = DecisionTreeClassifier(max_depth=max_depth, random_state=42)`) to ensure consistency in results.\n",
    "\n",
    "Follow these steps to find the optimal `max_depth`:\n",
    "* Iterate through `max_depth` values from 1 to 20.\n",
    "* Train the Decision Tree Classifier with the current `max_depth` parameter.\n",
    "* Optionally, visualize how the 'head' of each fitted tree changes with more advanced (=deep) trees. You can use the [`sklearn.tree.plot_tree()`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html) function, or the compact way  with the `export_text()` functionality ([Stack Overflow example](https://stackoverflow.com/questions/20156951/how-do-i-find-which-attributes-my-tree-splits-on-when-using-scikit-learn)):\n",
    "  ```\n",
    "  from sklearn.tree import export_text\n",
    "  tree_rules = export_text(model, feature_names=list(X_train), max_depth=3)\n",
    "  print(tree_rules)\n",
    "  ```\n",
    "* Calculate the precision score (you can use the function [sklearn.metrics.precision_score()](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html)) on the TEST dataset for each of the fitted trees. You can also compare it with the precision score on a VALIDATION dataset, which is included to the training phase (to have more data to train on). You should see that the precision score on a VALIDATION set starts to grow with the complexity of a tree (overfit), which isn't seen on the precision score on TEST.\n",
    "* Identify the optimal `max_depth`, where the  precision score is the highest on the TEST dataset. Record this value as  **best_max_depth** and submit as an answer.\n",
    "* Make predictions on all records (TRAIN+VALIDATION+TEST) and add the new prediction `pred6_clf_best` to the dataframe `new_df`.\n",
    "\n",
    "Additionally, compare the precision score of the tuned decision tree with previous predictions. You should observe an improvement (>0.58, or more than 58% precision), indicating that the tuned tree outperforms previous manual \"hand\" rules and Decision Tree predictions.\n",
    "\n",
    "ADVANCED: Read more about different aspects of [scikit-learn Decision Trees](https://scikit-learn.org/stable/modules/tree.html). Draw a line of precision/accuracy vs. max_depth and note whether there's a saturation point of precision/accuracy as max_depth increases. In theory, there should be a trade-off between better fitting (=more complex trees) and generalization."
   ]
  },
  {
   "cell_type": "code",
   "id": "c1c098f7aa1458ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-16T02:01:52.384262Z",
     "start_time": "2024-06-16T01:57:01.171141Z"
    }
   },
   "source": [
    "max_depth = 20\n",
    "test_precision = []\n",
    "\n",
    "for depth in range(1, max_depth+1):\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=SEED)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    test_precision.append(precision)\n",
    "\n",
    "print(f\"The optimal tree depth (from 1 to 20) for a DecisionTreeClassifier is {np.argmax(test_precision) + 1}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal tree depth (from 1 to 20) for a DecisionTreeClassifier is 15\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "3aa96e80141fae0f",
   "metadata": {},
   "source": [
    "## [EXPLORATORY] Question 5: What data is missing? \n",
    "\n",
    "Now that you have some insights from the correlation analysis and the Decision Trees regarding the most influential variables, suggest new indicators you would like to include in the dataset and explain why.\n",
    "\n",
    "You can also propose something entirely different based on your intuition, but it should be relevant to the shared dataset of the largest Indian, EU, and US stocks. If you choose this approach, please specify the data source as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd229488791610a",
   "metadata": {},
   "source": [
    "## Submitting the solutions\n",
    "\n",
    "Form for submitting: https://courses.datatalks.club/sma-zoomcamp-2024/homework/hw03"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
